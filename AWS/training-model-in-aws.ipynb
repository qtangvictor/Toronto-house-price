{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "bucket = 'toronto-house-price-project'\n",
    "prefix='input'\n",
    "prefix_output='models'\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost',repo_version='1.0-1') # built-in xgboost\n",
    "train_data = 's3://{}/{}/{}'.format(bucket, prefix, 'train')\n",
    "validation_data = 's3://{}/{}/{}'.format(bucket, prefix, 'validation')\n",
    "\n",
    "train_channel = sagemaker.session.s3_input(train_data, content_type='text/csv')\n",
    "valid_channel = sagemaker.session.s3_input(validation_data, content_type='text/csv')\n",
    "data_channels = {'train': train_channel, 'validation': valid_channel}\n",
    "\n",
    "s3_output_location = 's3://{}/{}/{}'.format(bucket, prefix_output, 'xgboost_model')\n",
    "xgb_model = sagemaker.estimator.Estimator(container,role,train_instance_count=1,train_instance_type='ml.m4.xlarge',train_volume_size = 1,output_path=s3_output_location,sagemaker_session=sagemaker.Session())\n",
    "xgb_model.set_hyperparameters(max_depth = 7,eta = 0.01,gamma = 0.1,min_child_weight = 1,num_round = 5000,eval_metric = 'rmse',objective='reg:linear')\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=True)\n",
    "#xgb_model.fit({'train':train_channel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,content_type='text/csv',instance_type='ml.t2.medium',endpoint_name='endpoint-v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "bucket = 'toronto-house-price-project'\n",
    "file_name = 'input/test.csv'\n",
    "s3 = boto3.resource('s3')\n",
    "obj = s3.Object(bucket, file_name)\n",
    "test_data_array = pd.read_csv(obj.get()['Body'],header=None)\n",
    "test_data_array = np.array(test_data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data_array[1] # select a row as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "\n",
    "predictions = xgb_predictor.predict(test_data).decode('utf-8') # predict!\n",
    "\n",
    "#predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# terminate end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor_1.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location of the test dataset\n",
    "batch_input = 's3://{}/{}/test.csv'.format(bucket, prefix)\n",
    "# The location to store the results of the batch transform job\n",
    "batch_output = 's3://{}/{}/batch-inference'.format(bucket, 'output')\n",
    "transformer = xgb_model.transformer(instance_count=1, instance_type='ml.m4.xlarge',output_path=batch_output)\n",
    "transformer.transform(data=batch_input, content_type='text/csv')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create endpoint from existing model artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retreve model from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "#image_name = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost',repo_version='1.0-1') # built-in xgboost\n",
    "s3_model_location = r's3://toronto-house-price-project/models/xgboost_model/sagemaker-xgboost-2020-10-19-17-51-06-651/output/model.tar.gz'\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "xgb_model_1 = sagemaker.model.Model (model_data = s3_model_location, \n",
    "                               image = container,\n",
    "                               role = role,\n",
    "                               sagemaker_session = sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy the model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify endpoint instance type and count\n",
    "#deploy endpoint\n",
    "xgb_model_1.deploy(initial_instance_count = 1,instance_type = 'ml.t2.medium',endpoint_name='endpoint-xgboost') # need to change endpoint name every time, otherwise the name will conflict with the existing one\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a real time predictor with the deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name='endpoint-v3'\n",
    "xgb_predictor_1=sagemaker.predictor.RealTimePredictor(endpoint=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load test data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "bucket = 'toronto-house-price-project'\n",
    "file_name = 'input/test.csv'\n",
    "s3 = boto3.resource('s3')\n",
    "obj = s3.Object(bucket, file_name)\n",
    "test_data_array = pd.read_csv(obj.get()['Body'],header=None)\n",
    "test_data_array = np.array(test_data_array)\n",
    "test_data=test_data_array[1046]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "xgb_predictor_1.content_type = 'text/csv' # set the data type for an inference\n",
    "\n",
    "xgb_predictor_1.serializer = csv_serializer # set the serializer type\n",
    "\n",
    "predictions = xgb_predictor_1.predict(test_data).decode('utf-8') # predict!\n",
    "\n",
    "#predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.predictor import csv_serializer    # Converts strings for HTTP POST requests on inference\n",
    "\n",
    "import numpy as np                                # For performing matrix operations and numerical processing\n",
    "import pandas as pd                               # For manipulating tabular data\n",
    "from time import gmtime, strftime                 \n",
    "import os \n",
    " \n",
    "region = boto3.Session().region_name    \n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "bucket = 'toronto-house-price-project'\n",
    "prefix = 'sagemaker/DEMO-automatic-model-tuning-xgboost-dm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "      \"CategoricalParameterRanges\": [],\n",
    "      \"ContinuousParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"1\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"eta\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"2\",\n",
    "          \"MinValue\": \"0\",\n",
    "          \"Name\": \"alpha\"\n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"min_child_weight\"\n",
    "        }\n",
    "      ],\n",
    "      \"IntegerParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"10\",\n",
    "          \"MinValue\": \"1\",\n",
    "          \"Name\": \"max_depth\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "      \"MaxNumberOfTrainingJobs\": 20,\n",
    "      \"MaxParallelTrainingJobs\": 3\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "      \"MetricName\": \"validation:mape\",\n",
    "      \"Type\": \"Maximize\"\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "\n",
    "s3_input_train = 's3://{}/{}/train'.format(bucket, prefix)\n",
    "s3_input_validation ='s3://{}/{}/validation/'.format(bucket, prefix)\n",
    "     \n",
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "      \"TrainingImage\": training_image,\n",
    "      \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "      {\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"CompressionType\": \"None\",\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": s3_input_train\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"ChannelName\": \"validation\",\n",
    "        \"CompressionType\": \"None\",\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": s3_input_validation\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\n",
    "      \"S3OutputPath\": \"s3://{}/{}/output\".format(bucket,prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "      \"InstanceCount\": 2,\n",
    "      \"InstanceType\": \"ml.c4.2xlarge\",\n",
    "      \"VolumeSizeInGB\": 10\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"StaticHyperParameters\": {\n",
    "      \"eval_metric\": \"auc\",\n",
    "      \"num_round\": \"100\",\n",
    "      \"objective\": \"binary:logistic\",\n",
    "      \"rate_drop\": \"0.3\",\n",
    "      \"tweedie_variance_power\": \"1.4\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "      \"MaxRuntimeInSeconds\": 43200\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name = \"MyTuningJob\"\n",
    "smclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name,\n",
    "                                           HyperParameterTuningJobConfig = tuning_job_config,\n",
    "                                           TrainingJobDefinition = training_job_definition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
